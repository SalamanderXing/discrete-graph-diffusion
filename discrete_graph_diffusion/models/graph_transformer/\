from flax import linen as nn
from jax import numpy as jnp
from .layers import XToY, EToY

class NodeEdgeBlock(nn.Module):
    """Self attention layer that also updates the representations of the edges."""

    def __init__(self, dx, de, dy, n_head, **kwargs):
        super().__init__()
        assert dx % n_head == 0, f"dx ({dx}) must be divisible by n_head ({n_head})"
        self.dx = dx
        self.de = de
        self.dy = dy
        self.df = dx // n_head
        self.n_head = n_head

        # Attention
        self.q = nn.Dense(dx, use_bias=False, dtype=jnp.float32)
        self.k = nn.Dense(dx, use_bias=False, dtype=jnp.float32)
        self.v = nn.Dense(dx, use_bias=False, dtype=jnp.float32)

        # FiLM E -> X
        # the following matrix must have size (de, dx)
        self.e_add = nn.Dense(dx, use_bias=False, dtype=jnp.float32)
        self.e_mul = nn.Dense(dx, use_bias=False, dtype=jnp.float32)

        # FiLM Y -> E
        # the following matrix must have size (dy, dx)
        self.y_e_mul = nn.Dense(dx, use_bias=False, dtype=jnp.float32)
        self.y_e_add = nn.Dense(dx, use_bias=False, dtype=jnp.float32)

        # FiLM Y -> X
        # the following matrix must have size (dy, dx)
        self.y_x_mul = nn.Dense(dx, use_bias=False, dtype=jnp.float32)
        self.y_x_add = nn.Dense(dx, use_bias=False, dtype=jnp.float32)

        # Process y 
        self.y_y = nn.Dense(dy, use_bias=False, dtype=jnp.float32)
        self.x_y = XToY()
        self.e_y = EToY()



